{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57cd68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Processed Logistic</th>\n",
       "      <td>0.11831</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0.685294</td>\n",
       "      <td>0.12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Processed XGBoost</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.931239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Processsed XGBoost (Recall_opt)</th>\n",
       "      <td>0.105134</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.187364</td>\n",
       "      <td>0.634314</td>\n",
       "      <td>1.263573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Processed LightGBM</th>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.312057</td>\n",
       "      <td>0.904809</td>\n",
       "      <td>(0, 87565)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                precision recall  f1-score  accuracy  \\\n",
       "Processed Logistic                0.11831   0.84  0.207407  0.685294   \n",
       "Processed XGBoost                0.333333    0.1  0.153846  0.946078   \n",
       "Processsed XGBoost (Recall_opt)  0.105134   0.86  0.187364  0.634314   \n",
       "Processed LightGBM               0.241758   0.44  0.312057  0.904809   \n",
       "\n",
       "                                time_seconds  \n",
       "Processed Logistic                   0.12345  \n",
       "Processed XGBoost                   0.931239  \n",
       "Processsed XGBoost (Recall_opt)     1.263573  \n",
       "Processed LightGBM                (0, 87565)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path.cwd().parent.parent / \"data\" / \"results\"\n",
    "\n",
    "lo_raw = pd.read_csv(results_dir / \"logistic_regression_raw_metrics.csv\", index_col=0)\n",
    "lo_processed = pd.read_csv(results_dir / \"logistic_regression_processed_metrics.csv\", index_col=0)\n",
    "logistic_processed = pd.read_csv(results_dir / \"confusion_matrix_logistic_processed.csv\", index_col=0)\n",
    "TN1 = logistic_processed.loc[\"Actual_0\", \"Pred_0\"]\n",
    "FP1 = logistic_processed.loc[\"Actual_0\", \"Pred_1\"]\n",
    "FN1 = logistic_processed.loc[\"Actual_1\", \"Pred_0\"]\n",
    "TP1 = logistic_processed.loc[\"Actual_1\", \"Pred_1\"]\n",
    "# Compute metrics\n",
    "precision_lo = TP1 / (TP1 + FP1)\n",
    "recall_lo = TP1 / (TP1 + FN1)\n",
    "f1_lo = 2 * precision_lo * recall_lo / (precision_lo + recall_lo)\n",
    "accuracy_lo = (TP1 + TN1) / (TP1 + TN1 + FP1 + FN1)\n",
    "\n",
    "xgb_raw = pd.read_csv(results_dir / \"xgboost_processed_raw.csv\", index_col=0)\n",
    "xgb_processed = pd.read_csv(results_dir / \"xgboost_variants_metrics.csv\", index_col=0)\n",
    "row_0_5 = xgb_processed.query(\"variant == 'default_0.5'\").iloc[0]\n",
    "row_Recall = xgb_processed.query(\"variant == 'Recall_opt'\").iloc[0]\n",
    "row_F2 = xgb_processed.query(\"variant == 'F2_opt'\").iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "# lightgbm_raw = pd.read_csv(results_dir / \"lightgbm_raw_metrics.csv\", index_col=0)\n",
    "lightgbm_processed = pd.read_csv(results_dir / \"confusion_matrix_lightgbm.csv\", index_col=0)\n",
    "# Extract confusion matrix values\n",
    "TN = lightgbm_processed.loc[\"Actual_0\", \"Pred_0\"]\n",
    "FP = lightgbm_processed.loc[\"Actual_0\", \"Pred_1\"]\n",
    "FN = lightgbm_processed.loc[\"Actual_1\", \"Pred_0\"]\n",
    "TP = lightgbm_processed.loc[\"Actual_1\", \"Pred_1\"]\n",
    "\n",
    "# Compute metrics\n",
    "precision_lgb = TP / (TP + FP)\n",
    "recall_lgb = TP / (TP + FN)\n",
    "f1_lgb = 2 * precision_lgb * recall_lgb / (precision_lgb + recall_lgb)\n",
    "accuracy_lgb = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# N·∫øu b·∫°n c√≥ time ·ªü file kh√°c th√¨ ƒë·∫∑t v√†o, c√≤n kh√¥ng th√¨ 0\n",
    "time_lgb = 0,87565\n",
    "\n",
    "\n",
    "metrics = [\"precision\", \"recall\", \"f1-score\", \"accuracy\", \"time_seconds\"]\n",
    "\n",
    "# T·∫°o dict ƒë·ªÉ tr√°nh l·ªói transpose\n",
    "data = {\n",
    "    # \"Raw Logistic\": [\n",
    "    #     lo_raw.loc[m, \"weighted avg\"] if m in [\"precision\",\"recall\",\"f1-score\"] \n",
    "    #     else lo_raw.loc[m, lo_raw.columns[0]]\n",
    "    #     for m in metrics\n",
    "    # ],\n",
    "    # \"Processed Logistic\": [\n",
    "    #     lo_processed.loc[m, \"weighted avg\"] if m in [\"precision\",\"recall\",\"f1-score\"] \n",
    "    #     else lo_processed.loc[m, lo_processed.columns[0]]\n",
    "    #     for m in metrics\n",
    "    # ],\n",
    "    \"Processed Logistic\": [\n",
    "        precision_lo,\n",
    "        recall_lo,\n",
    "        f1_lo,\n",
    "        accuracy_lo,\n",
    "        0.12345,  # Thay gi√° tr·ªã th·ªùi gian th·ª±c t·∫ø n·∫øu c√≥\n",
    "    ],\n",
    "    # \"Raw XGBoost\": [\n",
    "    #     xgb_raw.loc[m, \"weighted avg\"] if m in [\"precision\",\"recall\",\"f1-score\"] \n",
    "    #     else xgb_raw.loc[m, xgb_raw.columns[0]]\n",
    "    #     for m in metrics\n",
    "    # ],\n",
    "    \"Processed XGBoost\": [\n",
    "        row_0_5[m] for m in metrics\n",
    "    ],\n",
    "    \"Processsed XGBoost (Recall_opt)\": [\n",
    "        row_Recall[m] for m in metrics\n",
    "    ],\n",
    "    # \"Processsed XGBoost (F2_opt)\": [\n",
    "    #     row_F2[m] for m in metrics\n",
    "    # ],\n",
    "    \n",
    "    # \"Raw LightGBM\": [\n",
    "    #     lightgbm_raw.loc[m, \"weighted avg\"] if m in [\"precision\",\"recall\",\"f1-score\"] \n",
    "    #     else lightgbm_raw.loc[m, lightgbm_raw.columns[0]]\n",
    "    #     for m in metrics\n",
    "    # ],\n",
    "    \"Processed LightGBM\": [\n",
    "    precision_lgb,\n",
    "    recall_lgb,\n",
    "    f1_lgb,\n",
    "    accuracy_lgb,\n",
    "    time_lgb,\n",
    "    ],\n",
    "\n",
    "    #     lightgbm_processed.loc[m, \"weighted avg\"] if m in [\"precision\",\"recall\",\"f1-score\"] \n",
    "    #     else lightgbm_processed.loc[m, lightgbm_processed.columns[0]]\n",
    "    #     for m in metrics\n",
    "    # ],\n",
    "}\n",
    "\n",
    "# Metric l√† index, kh√¥ng ph·∫£i c·ªôt\n",
    "comparison = pd.DataFrame(data, index=metrics)\n",
    "\n",
    "# Chuy·ªÉn v·ªã\n",
    "comparison_T = comparison.transpose()\n",
    "\n",
    "# L∆∞u file kh√¥ng index\n",
    "# comparison_T.to_csv(results_dir / \"logistic_comparison.csv\", index=False)\n",
    "comparison_T.to_csv(results_dir / \"model_comparison.csv\", index=True)\n",
    "\n",
    "comparison_T.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cdc61ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: d:\\Khai ph√° d·ªØ li·ªáu\\Stroke-Prediction-Project\\data\\results\\precision_plot.png\n",
      "Saved: d:\\Khai ph√° d·ªØ li·ªáu\\Stroke-Prediction-Project\\data\\results\\recall_plot.png\n",
      "Saved: d:\\Khai ph√° d·ªØ li·ªáu\\Stroke-Prediction-Project\\data\\results\\f1_plot.png\n",
      "Saved: d:\\Khai ph√° d·ªØ li·ªáu\\Stroke-Prediction-Project\\data\\results\\accuracy_plot.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def random_colors(n):\n",
    "    return [\"#\" + ''.join(random.choices('0123456789ABCDEF', k=6)) for _ in range(n)]\n",
    "\n",
    "metric_colors = {\n",
    "    \"precision\": \"#4da6ff\",     # xanh d∆∞∆°ng\n",
    "    \"recall\": \"#ff884d\",        # cam\n",
    "    \"f1-score\": \"#cc66ff\",      # t√≠m\n",
    "    \"accuracy\": \"#66cc66\",      # xanh l√°\n",
    "    \"time_seconds\": \"#ff6666\",  # ƒë·ªè\n",
    "}\n",
    "\n",
    "\n",
    "results_dir = Path.cwd().parent.parent / \"data\" / \"results\"\n",
    "df = pd.read_csv(results_dir / \"model_comparison.csv\")\n",
    "\n",
    "# ƒê·∫∑t ƒë√∫ng index = Model\n",
    "# if \"Model\" in df.columns:\n",
    "#     df = df.set_index(\"Model\")\n",
    "\n",
    "def plot_metric(df, metric, title):\n",
    "    color = metric_colors.get(metric, \"skyblue\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(df.index, df[metric], color=color)\n",
    "\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(metric, fontsize=12)\n",
    "    plt.xlabel(\"Model\", fontsize=12)\n",
    "\n",
    "    # üî• CH·ªàNH FONT CHO NH·ªé L·∫†I & N·∫∞M NGANG\n",
    "    plt.xticks(rotation=0, ha=\"center\", fontsize=8)\n",
    "\n",
    "    # Hi·ªÉn th·ªã gi√° tr·ªã l√™n ƒë·∫ßu c·ªôt\n",
    "    for x, y in zip(df.index, df[metric]):\n",
    "        plt.text(x, y, f\"{y:.5f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df.index = [\n",
    "    # \"Raw Logistic\",\n",
    "    \"Processed Logistic\",\n",
    "    # \"Raw XGBoost\",\n",
    "    \"Processed XGBoost\",\n",
    "    \"XGBoost (Recall_opt)\",\n",
    "    # \"XGBoost (F2_opt)\",\n",
    "    \"Processed LightGBM\"\n",
    "]\n",
    "\n",
    "# plot_metric(df, \"time_seconds\", \"So s√°nh Th·ªùi gian hu·∫•n luy·ªán gi·ªØa c√°c m√¥ h√¨nh Machine Learning\")\n",
    "def plot_and_save(df, metric, title, filename):\n",
    "    color = metric_colors.get(metric, \"skyblue\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(df.index, df[metric], color=color)\n",
    "\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(metric, fontsize=12)\n",
    "    plt.xlabel(\"Model\", fontsize=12)\n",
    "\n",
    "    plt.xticks(rotation=15, ha=\"right\", fontsize=8)\n",
    "\n",
    "    for x, y in zip(df.index, df[metric]):\n",
    "        plt.text(x, y, f\"{y:.5f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = results_dir / filename\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "\n",
    "plot_and_save(df, \"precision\", \"So s√°nh Precision gi·ªØa c√°c m√¥ h√¨nh\", \"precision_plot.png\")\n",
    "plot_and_save(df, \"recall\", \"So s√°nh Recall gi·ªØa c√°c m√¥ h√¨nh\", \"recall_plot.png\")\n",
    "plot_and_save(df, \"f1-score\", \"So s√°nh F1-score gi·ªØa c√°c m√¥ h√¨nh\", \"f1_plot.png\")\n",
    "plot_and_save(df, \"accuracy\", \"So s√°nh Accuracy gi·ªØa c√°c m√¥ h√¨nh\", \"accuracy_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b96c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
